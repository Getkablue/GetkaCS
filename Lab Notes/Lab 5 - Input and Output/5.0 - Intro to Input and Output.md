We are generally familiar with the idea of program output already. Whenever we've used `std::cout` from C++ for example, we are creating output that displays in the terminal where we ran our program. In fact, our Hello World program did this. You may have created a program which also *accepts* input using `std::cin` in C++ or `scanf` in C. 

In both cases, we are relying on writing, or reading, output from a known location associated with the terminal the program was run from. This is sort of the most basic form of  input and output ("I/O" or just "IO") that we can think of.

# IO from the Shell

Let's start with something that is more "IT" than "software engineering".

We can cause the output of any command to be directed to a file (which will be overwritten):
``` bash
echo "There would be nothing left" > output.txt
```
Or you can do the same, but append to the end of the file instead of overwrite:
``` bash
echo "of me." >> output.txt
```

In fact, you can do the opposite, to feed a file into the standard input stream (also called *stdin*):
``` bash
someprogram < input.txt
```

Or even redirect both input and output:
``` bash
someprogram < input.txt > output.txt
```

Usually there are three "standard streams": *stdin*, *stdout* and *stderr*. You can redirect these streams *separately* from one another -- nothing actually stops you from creating a separate terminal (or file) each for input, regular output or error output!
``` bash
# Redirect input.txt to stdin, stdout to output.log, stderr to errors.log
someprogram < input.txt > output.log 2> errors.log
```

There are even more advanced techniques which involve using the "|" (*pipe*) character to reroute stdout from one process to stdin for another.

You may have noticed that what is being produced by the *program* is not actually a file itself -- we're just taking the *streamed output* from that program and placing it in a file. Of course, we can make files from within a program too, without streaming anything out to the standard output streams.

Actually, in UNIX based systems like Linux, the *terminal streams themselves* are represented as files which can be written to. On those systems, even devices are often represented as files -- so you send data to a device just by putting it in the corresponding file. Interesting, but not important for now.

Anyway, shell-based IO streaming like this can be very powerful for day to day tasks. For example, just by piping input and output between commands, you could make a shell script that looks recursively through all subdirectories of a starting point, finds all files ending in ".names", reads those names, sorts them, counts the unique names and shows you the most and least common ones. Linux usually comes pre-installed with a lot more utilities than Windows in this regard, but Windows has some similarly powerful tools in PowerShell. Of course, this is just composing multiple smaller programs (like `cat`, `head`, `tail`, `sort`, `uniq`, `find`...) which each individually handle one task. [This guide](https://www.shellscript.sh/) provides an intro to creating shell scripts. You don't need to read it now, but if you are interested in working on Linux then give it a look.

# Program Arguments as Input
Sometimes when we run a program, we provide flags on the command line to indicate something we want the program to do. For instance, we might open a text editor by passing it the name of a file to open initially. Or we might pass "-h" or "--help" or "--usage" to get a menu which tells us how to use the program. 

These are *arguments* (alternatively *parameters*) to our program. At this point you should be very familiar with this concept from functions. Remember that our program entrypoint in C/C++, `main`, is *also a function!* Depending on your programming environment, your Hello World program may or may not have come with *arguments to main*:
``` cpp
int main(int argc, char** argv) { 
	// blah
}
# or sometimes (much worse use of syntax in my humble opinion)
int main(int argc, char *argv[])
```

These arguments are automatically populated when our program is run. `argc` is the integer number of arguments. `argv` is slightly more inscrutable. Based on the definitions above, can you guess what it means?

`argv` is an "array of `char*`", or "a pointer to pointers of char", depending on how you read it. In the C world, `char*` very often points to a string. String operations in C start from that `char*` and continue until they reach a NULL byte, the *string terminator*. Hence, a` char* []` or a `char**` are basically interchangeable as an array of null-terminated strings. Remember, both Windows and Linux were built on C, so they use these same conventions. As you might've guessed by now, these contain the arguments to our program, in the order that they were provided. You may remember from the basic computing review that we needed to disambiguate when spaces were part of a single argument or when they were there to separate arguments.

Anyway, it is extremely common to use the contents of `argv` to control your program's basic behavior. But this logic has to be written. Many libraries provide easier solutions for this than requiring you to write your own. In Python, `argparse` is a very nice and easy library for this purpose. In C++, the Qt framework includes something for this (honestly, it contains something for *way too many things*, but I digress). 

Actually, speaking of Python, it has no main entrypoint usually, besides the top of whatever script file is run. You can still access the command-line arguments with `import sys; print(sys.argv)` or something similar.

Creating a nice command-line interface can make your program very configurable and very attractive to power-users, especially for the kind of people who spend multiple hours each week customizing and automating their Arch Linux desktop.

# OK, but what about files?

In the next set of notes, we'll generalize our IO so that we can work with files, too.