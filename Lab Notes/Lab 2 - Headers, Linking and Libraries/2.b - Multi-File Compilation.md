Remember when we used `#include <stdio.h>` and `#include <iostream>`? I mentioned that these were *preprocessor directives* which include *header files*. In C++, header files (usually with the ".h" extension) contain additional code. While C++ does not enforce that header files contain any particular type of thing, the community tends to use header files in a specific way, and to separate them semantically from ".cpp" files which are also called *implementation files*.  In this scheme, header files act as the easiest way for you to make connections between different files in your program, and to link to other libraries. 

# Toolchain Technical Concepts

Let's review some of the stages of real-world compiling. A set of tools needed to build programs is usually called a *toolchain*. For example, MSVC, Clang and GCC are all separate toolchains for building Windows programs. Visual Studio is  **just a front end** which is built to work well with the MSVC toolchain -- nothing stops you from using any other toolchain on the underlying side. Do note that there are minor variations between compilers in terms of performance, meaning of certain code, strictness with warnings/errors, etcetera. For us in this course, MSVC is enough.

## Preprocessing
This is the first stage invoked by the toolchain when you tell it to build a program.

At this stage, the *preprocessor* program loads the file selected for compilation and reads them, looking for directives on lines that start with `#` . They have the general form `#DIRECTIVE ARGS`.
It preprocesses the file according to those directives. In the case of `#include <header>` or `include "header.h"`, it will look for the file `header.h` and include the *full content of that file* in the current file at the current location. It preprocesses that content, too. Incidentally, this means that the same header can be included multiple times, which almost always causes errors later (use `#pragma once` at the top of your header file to stop this). Similarly, if you forget to close a brace in a header, the parser now thinks the entire rest of your program is supposed to be inside that block... be careful!

Note also that other preprocessor directives exist, like defining macros -- macros can basically considered simple functions which run during preprocessing, and which take source code as input and produce source code as output. These sorts of macros and definitions can be used to add parameters for *how your software is built*, like disabling certain features from ever even being compiled by clicking a checkbox, or adapting your code to different platforms, or even as a hacky way to add language features.

Anyway, the preprocessed text output is what is actually passed to the next step.

## Compilation
This step takes preprocessed source code, which is now in one or more blobs. The compiler parser accepts these blobs of source code, parses them for their meaning, and performs the translation, where possible, into machine code instructions for the target platform. (It is sometimes said to "emit" blobs of Assembly, which are converted into blobs of machine code via an assembler process.).

However, the binary blobs which are produced here are not a *complete* binary. The compiler produces what are called *object code* files, often ending in ".o", but they are not in a format sufficient for execution as a process -- not all symbols used in the code are fully resolved at this point.

## Linking
This step is called *linking* -- so named because it helps *link* all of our code together into the finished product.

Linking is a multi-step process of arranging those blobs of binary code into various segments, ordering those segments, putting those segments into the right structure to be read as a valid executable file (for example, the Windows Portable Executable (PE) format), and fully resolving any unresolved symbols.

Multiple executable formats could exist on any given platform. But the OS determines how to read an executable file -- for example, if a file has the right "magic numbers" included to actually be valid code, and if code is in the right expected locations (probably after any metadata), and so on. The executable format is just a specification for these. On Linux, ELF is the most common format, while PE is most common on Windows (although COM files are also accepted as executables). For this course, don't worry about these concerns -- this is a topic for reverse engineering.

When we talk about *resolving symbols*, what do we mean? 

Consider the simple case of a function `functionA` that calls another function, `functionB`. These both exist as segments of some binary blob(s). In order for that to happen at the level of executable machine code, we need to know the address of the instructions to load and execute. A similar thing is true for consts and variables: we need to know what segment of memory to load when reading them or where to change when writing them. Hence, some *symbol* like "fn:functionB", which is supposed to point to where `functionB` *will be*, needs to be filled in with the actual location/address. The linker makes decisions for us about where all these variables, consts, and functions should be in the final executable, then fills in the symbols in every blob with the appropriate information before putting them all together.

The linker also handles one form of *dynamic linking*. As we mentioned in the computing review, some libraries are *dynamic libraries* (".dll", for Dynamic Link Library, also known as *shared objects*, ".so" files) which exist as separate binary files, and some libraries exist as *static libraries* which are linked (and bundled) directly into the finished executable. If we are to locate, load and use code from a dynamic library at runtime, that code (or at least, code which calls out to the system to do it for us) needs to be inserted. In this form, our executable also encodes the fact that it needs such a DLL in order to function, and Windows will scream at us early if those DLLs are missing at the time the program is loading.

To be perfectly clear, we can also *manually* include code to load a shared object, and manually look for symbols inside it. In turn, this allows us to do interesting and flexible things -- for instance, we might load some hardware accelerator library for a device like a GPU, and if it doesn't exist (isn't installed), then we use slower software emulation instead. But this is a little beyond the scope of this course. 

# Header Files and Implementation Files

This is the most common pattern used in C and C++ development. It is important that you remember this pattern.

Remember how we talked about there was a difference between declaring and defining?

In this pattern, header (".h") files are used to *declare* classes, functions and variables, as well as to define constants.
Implementation (".cpp") files are used to *define* anything that was declared and needs definition.

This pattern has multiple benefits. 

For one, headers describe *what your software component does*, implementations describe *how it does them*. This means that headers are useful to *users* of your software component, not just other *developers* of your software component.

Second, splitting header and implementation files like this means that your compiler can parallelize, at least, the parsing and compilation steps. If multiple things rely on the same implementation, that implementation only needs to be compiled once for all of them. All of those other components only need the header to know that a symbol exists -- it can be filled in later by the linker. This makes compilation faster.

Third, we cluster parts of information that are relevant to each other. For example, by convention in object-oriented development, usually there is one header and one implementation file per class (there are notable exceptions). You can also define some free functions that interact with those objects in the same set of files, though this is up to taste. (Free functions are just functions you declare that are not in a class or struct, i.e. not bound to any particular object). You can additionally use directories to separate clusters of files.

# In Practice
You can actually use these parts of the toolchain independently if you like -- they are often separate command-line programs which accept parameters and options of their own. At some underlying level, any settings you set in Visual Studio basically get translated into these options. For example, VS includes all code files in your project by default, so that the compiler/linker don't yell that they can't find definitions/symbols.

You *might* be interested in seeing the output of the individual tools to better understand the process. Try doing this for some really simple program as an exercise if you are interested. Otherwise, take it as granted.

Some basic knowledge of the toolchain usually helps in diagnosing errors during build, too.

Naturally, your program entry point is just the entry point -- you don't need to have a header associated with "main.cpp" if it just contains your entry point. However, you will probably want to *include* headers related to other parts of your program so that you can access their functionality.

The .cpp files associated with headers cannot redefine the class itself, so they should redefine the functions in the class namespace. So, for example, if you have some header "Color.h" with the following contents:
``` cpp
#pragma once
class Color {
	int r, g, b;
	Color();
	int getBrightness();
};
```
then your implementation "Color.cpp" file might look like:
``` cpp
#include "Color.h"

Color::Color() {
	r = 0;
	g = 0;
	b = 0;
}

int Color::getBrightness() {
	return r + g + b;
}
```
And your main program file will also `#include "Color.h"`.

Anyway, **try the following now** (yes, even if you aren't interested):

Create a program which relies on more than one source code file. For instance, create a main.cpp file which contains a relatively bare entrypoint and one other function which it calls, and create a new class, with both headers and implementation files. Your main.cpp file should `#include` the class header, and the functions in main.cpp should use the class in some way.  Visual Studio may help you -- go to File and see if it has an option to easily create a new C++ class, or use the "Class Wizard" by right clicking in the Solution Explorer. It is possible that project settings may need to be tweaked to get this to work. Please Google these.

Next, make a program with yet another header/implementation combo (so main, header/impl pair 1, and header/impl pair 2). Make it so that the code in pair 1 requires code from pair 2, and main requires pair 1.

Now, tweak your previous program so that code in pairs 1 and 2 requires each other. For instance, create 2 classes, `Duck` and `Dog`, and give `Dog` a member function which uses objects of type `Duck` and give `Duck` a member function which uses objects of type `Dog`.

If you get errors about code being redefined/redeclared at this stage, think fast! I've taught you how to handle this situation earlier in this document. (Hint: think about the preprocessor).

Alternatively, you may sometimes get an error that one piece of code sees code that has not been defined. This can occur especially in complex systems where not all headers are necessarily included for whatever purpose you have in mind. In that case, be aware of the "forward declaration", used to tell code to shut up and be patient:

``` cpp
class Meatball; // "bare" forward class declaration, no definition at all

// Now this class can use Meatball even if the "real" Meatball definition doesn't exist yet
class Bowl { 
	std::vector<Meatball*> meatballs; // *may* error out without the above forward-declaration
	// ...
};

// ... At some point in the preprocessed code, the "real" meatball definition will become clear:
class Meatball {
	// ... blah blah blah
};
```


# Other Notes

## Namespaces

Finally, if you want to organize code even more, you can put your code inside a namespace. Namespaces are just like their own "area" of code, and you can access them in a couple different ways:

``` cpp
namespace GetkaLib;

// Explicitly declaring a class inside GetkaLib namespace
class GetkaLib::Meatball {
	 // blah blah blah...
}

// Explicitly use it with the namespace name...
GetkaLib::Meatball myMeatball;

// ... or use "using", which is scope-limited:
if (needASecondMeatball) {
	using namespace GetkaLib;
	Meatball mySecondMeatball; // This works!
}

Meatball myThirdMeatball; // ERROR: "using namespace GetkaLib" no longer in effect due to scope

```

For example, the entire standard library of C++ is declared in the `std` namespace and accessed with `std::`. Some special subareas of code get nested namespaces, like `std::chrono`. It's generally good practice to put all your code inside a namespace appropriate for your project. This ensures that if you make your code into a library and someone else uses it, your code won't conflict/overlap with theirs no matter how common and unimaginative your symbol names are.

# DLLs

## Using DLLs

To develop a program which links against a DLL, we should make sure of 2 things:
1. A suitable header for that DLL (usually given by the developer), which declares all the symbols in it, and
2. The (binary) DLL itself should be present on our system, perhaps in the same directory the executable will be built in. It may also be present in `C:/Windows/System32` or similar directories where libraries are loaded by default.

You will need to include the header, which should mark the symbols which the DLL has available within it. Most DLLs have headers which work also for programs importing the symbols, not just for the program exporting them.

Most Windows programs rely, at some level, on the Windows NT kernel DLL files, user32.dll and kernel32.dll -- those are the files that perform all of Windows' most core functionality. Think about this: If you made a program which did not link to the NT DLLs at all (or any other Windows libraries), is your program still a Windows program? In actuality, besides the executable format created which would need some changing, you could create software this way that runs directly on a processor with no OS required -- potentially your *own* operating system!

While we won't go *that* far in this course, we will make some of our own libraries, and we will learn to use libraries others have made, too.

## Making your own DLLs

To make your own DLLs, you will need a header (which you will make). If you want to distribute this DLL, you should also distribute the associated header. 

But you will run into an issue: typical symbols that you declare in a file aren't necessarily marked as being exported (so that the linker makes them available to people loading your DLL). By default they are kept internally accessible, not externally. The syntax used to mark a function as "exported" in this way depends on the toolchain, but is usually something like qualifying the function declaration as "dlexport" or passing the function declaration into a preprocessor macro. You will need to look this up to know how to do it. **So do that now for MSVC.**

Then make a new project which is a DLL, and use that same header in an executable project which uses that DLL. Define a function in the DLL, and call that function from the main executable.

I am being deliberately vague with this -- spread your wings and fly, you beautiful creature. However, I do offer one specific point of advice:

If you *just* mark your function (or whatever) as "dlexport", your program which uses the library will give errors. Why? Because you're telling it that *it* needs to export the symbols. The equivalent "dlimport" marks a symbol as being importable, which is what you want to use in your executable.

So how do DLL authors distribute their header? They either manually change the "dlexports" to "dlimports" before distributing the header, or they use a preprocessor macro which, *if the current project is the DLL project*, will use "dlexport", *otherwise* it uses "dlimport". This is a pretty elegant solution. But how do we know what the current project is? Usually this is provided as a parameter to the toolchain.

In a later lab, we will discuss some ways to make these parameters much more powerful and easy to configure for your programs using a *build system.* For now, it is sufficient to know that a build system controls how the various parts of the toolchain are invoked, in what order, and so on.

As an exercise, try creating such a header, along with the corresponding DLL and executable programs, which automatically switches between these modes depending on the project. (Hint: look up a guide on writing basic preprocessor macros).









